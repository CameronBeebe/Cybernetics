{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybernetic Game Theory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS ACTIVELY W.I.P. August 2020, JUST A SKETCH BEFORE CONVERTING TO FUNCTIONS ETC.\n",
    "# This notebook aims to illustrate a toy model of a cybernetic regulator along the lines of W.R. Ashby's work.\n",
    "# It is instructive to see the game-theoretic foundations of other popular regulators, like Artificial Neural Networks.\n",
    "# The regulator can \"learn\" a probability distribution of disturbances, using reinforcement learning.\n",
    "# The result is effective control, channeling the flow of information from the environment into desired outcomes (states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import scipy as sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a game matrix for two players: Environment and Regulator\n",
    "# Choose a goal for Regulator\n",
    "# Environment goes first (row_i)\n",
    "# Regulator goes second (column_j)\n",
    "# Outcome is matrix element m_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 6, 8, 6],\n",
       "       [5, 6, 3, 3, 7],\n",
       "       [6, 4, 0, 2, 1],\n",
       "       [9, 4, 8, 6, 9],\n",
       "       [7, 0, 5, 3, 8],\n",
       "       [6, 4, 1, 0, 9],\n",
       "       [2, 5, 7, 1, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_matrix = np.random.randint(10, size=(7,5))\n",
    "game_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows are plays (a.k.a. \"disturbances\") for the environment.  \n",
    "# Create vector to use for pandas index and later to link up with probabilities.\n",
    "rows = [i+1 for i in range(len(game_matrix))]\n",
    "df = pd.DataFrame(data = game_matrix, columns=['a','b','c','d','e'], index=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e\n",
       "1  0  1  6  8  6\n",
       "2  5  6  3  3  7\n",
       "3  6  4  0  2  1\n",
       "4  9  4  8  6  9\n",
       "5  7  0  5  3  8\n",
       "6  6  4  1  0  9\n",
       "7  2  5  7  1  6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment chooses play (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution for environmental \"plays\" or \"disturbances\".\n",
    "dist = np.random.dirichlet(alpha=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05290195 0.04599036 0.05520273 0.16762703 0.2817019  0.10534903\n",
      " 0.291227  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have probabilities summing to 1.\n",
    "print(dist)\n",
    "sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a play.\n",
    "environment_play = np.random.choice(df.index, size=1, p=dist)\n",
    "environment_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regulator chooses action (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81, 61,  5, 49, 19])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use a Polya urn instead to define probabilities of actions for the regulator.\n",
    "urn = np.random.randint(100, size=len(df.columns))\n",
    "urn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37674419, 0.28372093, 0.02325581, 0.22790698, 0.08837209])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of drawing from urn\n",
    "probs = np.array([(i/sum(urn)) for i in urn])\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose random draws from plays in the urn with probabilities according to the composition of the urn.\n",
    "# We actually just care to draw from the plays, and not from the urn itself, although the urn is what will be updated/reinforced.\n",
    "regulator_action = np.random.choice(df.columns, size=1, p=probs)\n",
    "regulator_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulator_action.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update/Reinforce the action of the regulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .item to get the value from the game table out of the locations (rows/columns) encoded in arrays.\n",
    "out = df.loc[environment_play.item(),regulator_action.item()]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We need to set a goal for the regulator to achieve.\n",
    "goal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define regulator as dictionary of plays and associated probabilities.\n",
    "regulator = dict(zip(df.columns,urn))\n",
    "regulator['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: reinforced the regulator's action b from 61 to 62\n",
      "now we need to recalculate the probabilities according to the reinforced urn\n"
     ]
    }
   ],
   "source": [
    "# Compare outcome with goal, and reinforce (increase probability) action which regulator took in response to environment.\n",
    "if out == goal:\n",
    "    print(\"success: reinforced the regulator's action\", regulator_action.item(), \"from\", regulator[regulator_action.item()], \"to\", regulator[regulator_action.item()]+1)\n",
    "    regulator[regulator_action.item()] += 1\n",
    "    print('now we need to recalculate the probabilities according to the reinforced urn')\n",
    "else: print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 81, 'b': 62, 'c': 5, 'd': 49, 'e': 19}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm updated urn.\n",
    "regulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " [0.375,\n",
       "  0.28703703703703703,\n",
       "  0.023148148148148147,\n",
       "  0.22685185185185186,\n",
       "  0.08796296296296297])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalculate probabilities and confirm that correct play increases in probability and all others go down.\n",
    "sum_reg = sum([regulator[i] for i in regulator])\n",
    "updated_probs = [regulator[i]/sum_reg for i in regulator]\n",
    "sum(updated_probs),updated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
