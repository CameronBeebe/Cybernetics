{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cybernetic Game Theory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS ACTIVELY W.I.P. August-October 2020.  Began transforming sketch into functions.  \n",
    "# Instead of deleting sketch work, I am just commenting out to preserve thought process.\n",
    "# Next step is to separate out functions and create new notebook/script to continue development.\n",
    "\n",
    "# This notebook aims to illustrate a toy model of a cybernetic regulator along the lines of W.R. Ashby's work.\n",
    "# It is instructive to see the game-theoretic foundations of other popular regulators, like Artificial Neural Networks.\n",
    "# The regulator can \"learn\" a probability distribution of disturbances, using reinforcement learning.\n",
    "# The result is effective control, channeling the flow of information from the environment into desired outcomes (states)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a game matrix for two players: Environment and Regulator\n",
    "# Choose a goal for Regulator\n",
    "# Environment goes first (row_i)\n",
    "# Regulator goes second (column_j)\n",
    "# Outcome is matrix element m_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 8, 9, 5],\n",
       "       [2, 6, 5, 9, 0],\n",
       "       [7, 6, 3, 2, 9],\n",
       "       [7, 9, 9, 9, 8],\n",
       "       [3, 3, 8, 6, 7],\n",
       "       [2, 5, 7, 6, 5],\n",
       "       [8, 2, 8, 7, 5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_matrix = np.random.randint(10, size=(7,5))\n",
    "game_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows are plays (a.k.a. \"disturbances\") for the environment.  \n",
    "# Create vector to use for pandas index and later to link up with probabilities.\n",
    "def create_game(size):\n",
    "    game_matrix = np.random.randint(10, size=size)\n",
    "    rows = [i+1 for i in range(len(game_matrix))]\n",
    "    print(rows)\n",
    "    return pd.DataFrame(data = game_matrix, columns=['a','b','c','d','e'], index=rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e\n",
       "1  5  7  8  2  7\n",
       "2  3  2  8  9  2\n",
       "3  8  4  0  7  9\n",
       "4  9  4  0  5  2\n",
       "5  3  7  7  4  0\n",
       "6  8  8  5  4  6\n",
       "7  8  9  9  4  2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = create_game((7,5))\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment chooses play (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution for environmental \"plays\" or \"disturbances\".\n",
    "#dist = np.random.dirichlet(alpha=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have probabilities summing to 1.\n",
    "#print(dist)\n",
    "#sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a play.\n",
    "def environment_play(game):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    dist = np.random.dirichlet(alpha=game.index)\n",
    "    return np.random.choice(game.index, size=1, p=dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_play = environment_play(game).item()\n",
    "env_play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regulator chooses action (column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 7, 5, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use a Polya urn instead to define probabilities of actions for the regulator.\n",
    "urn = np.random.randint(10, size=len(game.columns))\n",
    "urn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2 , 0.2 , 0.28, 0.2 , 0.12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilities of drawing from urn\n",
    "probs = np.array([(i/sum(urn)) for i in urn])\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random draws from plays in the urn with probabilities according to the composition of the urn.\n",
    "# We actually just care to draw from the plays, and not from the urn itself, although the urn is what will be updated/reinforced.\n",
    "def regulator_action(game,probs):\n",
    "    return np.random.choice(game.columns, size=1, p=probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_action = regulator_action(game,probs).item()\n",
    "reg_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update/Reinforce the action of the regulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .item to get the value from the game table out of the locations (rows/columns) encoded in arrays.\n",
    "out = game.loc[env_play,reg_action]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c  d  e\n",
       "1  5  7  8  2  7\n",
       "2  3  2  8  9  2\n",
       "3  8  4  0  7  9\n",
       "4  9  4  0  5  2\n",
       "5  3  7  7  4  0\n",
       "6  8  8  5  4  6\n",
       "7  8  9  9  4  2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convince yourself that this row/column outcome corresponds to the game.\n",
    "game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We need to set a goal for the regulator to achieve.\n",
    "goal = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 5, 'b': 5, 'c': 7, 'd': 5, 'e': 3}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define regulator as dictionary of plays and associated probabilities.\n",
    "regulator = dict(zip(game.columns,urn))\n",
    "regulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outcome with goal, and reinforce (increase probability) action which regulator took in response to environment.\n",
    "# It makes sense to reinforce individual successes more than we weaken, since we expect to fail a lot in the beginning.\n",
    "# Try adding len(regulator), although this may be impractical for some examples.\n",
    "#if out == goal:\n",
    "#    print(\"success: reinforced the regulator's action\", reg_action, \"from\", regulator[reg_action], \"to\", regulator[reg_action] + len(regulator))\n",
    "#    regulator[reg_action] += len(regulator)\n",
    "#    print('now we need to recalculate the probabilities according to the reinforced urn')\n",
    "#else: print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm updated urn.\n",
    "#regulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate probabilities and confirm that correct play increases in probability and all others go down.\n",
    "def prob_calc(regulator_dict):\n",
    "    sum_reg = np.array(sum([regulator_dict[i] for i in regulator_dict]))\n",
    "    return np.array([regulator_dict[i]/sum_reg for i in regulator_dict])\n",
    "    #sum(updated_probs),updated_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob_calc(regulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original probs\n",
    "#probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want the regulator to update when it fails.  How might this look?\n",
    "# Remember that the regulator's action distribution was random (the composition of the urn).  \n",
    "# Consider that the regulator was perhaps overconfident, how can we make the \"urn\" less \"confident\"?\n",
    "# Lets \"sqeeze\" the distribution in the urn, by making it less confident for any particular action.\n",
    "\n",
    "# We could make drastic changes to our distribution, but we should keep in mind that we may want to use \n",
    "# the same fail-update procedure over and over again in an automated learning process.  \n",
    "# If our \"squeeze\" is too drastic (e.g. making the urn parts equal / probabilities uniform) then even if\n",
    "# our regulator is \"learned\" but makes a mistake, it will \"forget\" the learned distribution.\n",
    "\n",
    "# We can still use the mean of the urn composition in a function that slightly squeezes, \n",
    "# incrementing those actions which are below the mean, and decrementing those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how multiple (failing) applications of this function will \"converge\" around the mean.\n",
    "# More precisely, it will slightly oscillate around the convergence point.\n",
    "def squeeze(regulator_dict, urn_list):\n",
    "    '''\n",
    "    This update function takes two arguments.\n",
    "    \n",
    "    regulator_dict: a regulator defined as a dictionary of key labels (plays or columns) \n",
    "    and integer values (from a distribution or urn).\n",
    "    \n",
    "    urn_list: a list of integers interpreted as the composition of a Polya urn.\n",
    "    \n",
    "    The function calculates the mean of the urn composition, and compares each value\n",
    "    in the regulator_dict with the mean.  \n",
    "    \n",
    "    The resulting regulator_dict is updated by incrementing values smaller than the\n",
    "    mean, and decrementing values greater than the mean.\n",
    "    \n",
    "    '''\n",
    "    mean = np.mean(urn_list)\n",
    "    for i in regulator_dict:\n",
    "        if regulator_dict[i] >= mean:\n",
    "            regulator_dict[i] -= 1\n",
    "            print('squeeze down:', regulator_dict[i])\n",
    "        else:\n",
    "            regulator_dict[i] += 1\n",
    "            print('squeeze up:', regulator_dict[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our new function which includes update protocols for both success and failure.\n",
    "def update(regulator_dict,action,out,goal,urn_list):\n",
    "    if out == goal:\n",
    "        #print(action)\n",
    "        print(\"success: reinforced the regulator's action\", action, \"from\", regulator_dict[action], \"to\", regulator_dict[action]+len(regulator_dict))\n",
    "        regulator_dict[action] += len(regulator_dict)\n",
    "        print('now we need to recalculate the probabilities according to the reinforced urn')\n",
    "    else:\n",
    "        print('fail: squeezing. (incrementally adjusting composition of regulator urn towards mean)')\n",
    "        squeeze(regulator_dict, urn_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: reinforced the regulator's action a from 5 to 10\n",
      "now we need to recalculate the probabilities according to the reinforced urn\n"
     ]
    }
   ],
   "source": [
    "update(regulator,reg_action,out,goal,urn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 10, 'b': 5, 'c': 7, 'd': 5, 'e': 3}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.16666667, 0.23333333, 0.16666667, 0.1       ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_calc(regulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2 , 0.2 , 0.28, 0.2 , 0.12])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original probabilities\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeeze??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "len?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets repetitively train the regulator on multiple disturbances from the environment\n",
    "# After each outcome, we will update, hoping to improve the likelihood of successful plays.\n",
    "\n",
    "def train(game,regulator,epochs):\n",
    "    urn = np.random.randint(100, size=len(game.columns))\n",
    "    probs = np.array([(i/sum(urn)) for i in urn])\n",
    "    i=1\n",
    "    while i <= epochs:\n",
    "        \n",
    "        # Environment chooses play.\n",
    "        play = environment_play(game)\n",
    "        \n",
    "        # Regulator chooses action.\n",
    "        action = regulator_action(game,probs)\n",
    "        \n",
    "        # \n",
    "        \n",
    "        # Recalculate regulator probabilities.\n",
    "        \n",
    "        \n",
    "        #Increment i.\n",
    "        i += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = type(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 'four'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'four'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
